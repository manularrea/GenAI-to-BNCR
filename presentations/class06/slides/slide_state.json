{
  "project_info": {
    "title": "Prompt Engineering para Aplicaciones Bancarias",
    "created": 1761590086.5745409,
    "last_updated": 1761590109.9688287,
    "total_slides": 11
  },
  "slides": {
    "title": "edited",
    "why_matters": "edit_pending",
    "anatomy": "edit_pending",
    "techniques_overview": "edit_pending",
    "zero_shot": "edit_pending",
    "few_shot": "edit_pending",
    "chain_of_thought": "edit_pending",
    "banking_patterns": "edit_pending",
    "best_practices": "edit_pending",
    "demo_preview": "edit_pending",
    "lab_transition": "edit_pending"
  },
  "outline": [
    {
      "id": "title",
      "title": "Prompt Engineering para Aplicaciones Bancarias",
      "summary": "Slide de título con información del curso: Generative AI for Banking Sector, BNCR, Instructor: Manuela Larrea, Clase 6 de 20",
      "image_plan": "",
      "slide_template_key": ""
    },
    {
      "id": "why_matters",
      "title": "Por Qué el Prompt Engineering Transforma Resultados",
      "summary": "El prompt engineering puede mejorar la precisión en 40-60% sin cambios en el modelo. En BNCR, esto significa respuestas más consistentes, menos escalaciones y mejor experiencia del cliente. Mostrar estadísticas de mejora y casos de uso bancarios.",
      "image_plan": "",
      "slide_template_key": ""
    },
    {
      "id": "anatomy",
      "title": "Anatomía de un Prompt Efectivo",
      "summary": "Los componentes esenciales de un prompt: Rol/Contexto (quién es el asistente), Instrucción (qué debe hacer), Contexto (información relevante), Formato (cómo responder), Restricciones (qué evitar). Incluir ejemplo visual con cada componente identificado.",
      "image_plan": "",
      "slide_template_key": ""
    },
    {
      "id": "techniques_overview",
      "title": "Tres Técnicas Fundamentales de Prompting",
      "summary": "Comparación visual de Zero-Shot (sin ejemplos), Few-Shot (con 2-5 ejemplos) y Chain-of-Thought (razonamiento paso a paso). Mostrar cuándo usar cada técnica y sus ventajas/desventajas en contexto bancario.",
      "image_plan": "",
      "slide_template_key": ""
    },
    {
      "id": "zero_shot",
      "title": "Zero-Shot: Simplicidad para Tareas Directas",
      "summary": "Zero-shot prompting solicita tareas sin ejemplos previos. Ideal para consultas simples y respuestas generales. Ejemplo bancario: explicar productos básicos. Limitación: menos preciso para tareas complejas o formatos específicos.",
      "image_plan": "",
      "slide_template_key": ""
    },
    {
      "id": "few_shot",
      "title": "Few-Shot: Aprendizaje por Ejemplos",
      "summary": "Few-shot proporciona 2-5 ejemplos antes de la tarea real. Mejora precisión en 30-50% y garantiza formato consistente. Ejemplo bancario: clasificación de intenciones del cliente (consulta saldo, transferencia, problema técnico). Mostrar antes/después.",
      "image_plan": "",
      "slide_template_key": ""
    },
    {
      "id": "chain_of_thought",
      "title": "Chain-of-Thought: Razonamiento Transparente",
      "summary": "Chain-of-thought solicita razonamiento paso a paso usando la frase clave 'piensa paso a paso'. Crítico para cumplimiento regulatorio en banca. Ejemplo: evaluación de elegibilidad de préstamo con razonamiento visible.",
      "image_plan": "",
      "slide_template_key": ""
    },
    {
      "id": "banking_patterns",
      "title": "Patrones de Prompts para BNCR",
      "summary": "Tres patrones reutilizables: 1) Clasificación de intenciones (categorizar consultas), 2) Extracción de información (obtener datos estructurados), 3) Generación personalizada (respuestas adaptadas al cliente). Cada patrón con template de código.",
      "image_plan": "",
      "slide_template_key": ""
    },
    {
      "id": "best_practices",
      "title": "Mejores Prácticas y Errores Comunes",
      "summary": "Mejores prácticas: claridad sobre creatividad, iteración basada en resultados, temperatura adecuada (0-0.3 para determinístico, 0.7-0.9 para creativo), validación de outputs críticos, versionado de prompts. Errores comunes: prompts ambiguos, falta de contexto, no validar resultados.",
      "image_plan": "",
      "slide_template_key": ""
    },
    {
      "id": "demo_preview",
      "title": "Demostración: Evolución de un Prompt",
      "summary": "Preview de la demo en vivo: mostraremos cómo un prompt básico evoluciona agregando contexto, ejemplos y formato. Comparación lado a lado de resultados. Caso de uso: clasificación de consultas bancarias con mejora de 45% a 92% de precisión.",
      "image_plan": "",
      "slide_template_key": ""
    },
    {
      "id": "lab_transition",
      "title": "Lab 06: Práctica con Casos Reales de BNCR",
      "summary": "En el Lab 06 practicarán: diseñar prompts para casos reales, implementar templates reutilizables, comparar técnicas de prompting, medir y optimizar resultados. Duración: 1.5 horas. Acceso al notebook en el repositorio GitHub.",
      "image_plan": "",
      "slide_template_key": ""
    }
  ]
}