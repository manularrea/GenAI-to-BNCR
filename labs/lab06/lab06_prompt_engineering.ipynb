{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 06: Prompt Engineering Fundamentals\n",
        "\n",
        "**Course:** Generative AI for Banking Sector  \n",
        "**Institution:** Banco Nacional de Costa Rica (BNCR)  \n",
        "**Instructor:** Manuela Larrea  \n",
        "**Duration:** 3 hours\n",
        "\n",
        "---\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this lab, you will be able to:\n",
        "\n",
        "1. Understand the principles of effective prompt engineering\n",
        "2. Apply zero-shot, one-shot, and few-shot learning techniques\n",
        "3. Use chain-of-thought prompting for complex reasoning\n",
        "4. Create structured outputs (JSON, tables, lists)\n",
        "5. Implement role-based prompting for banking scenarios\n",
        "6. Handle edge cases and improve prompt robustness\n",
        "7. Measure and improve prompt quality\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Azure Infrastructure for This Lab\n",
        "\n",
        "```\n",
        "\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n",
        "\u2551                  LAB 06 - AZURE INFRASTRUCTURE                           \u2551\n",
        "\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n",
        "\n",
        "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "\u2502                        YOU (Jupyter Notebook)                            \u2502\n",
        "\u2502                                                                           \u2502\n",
        "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n",
        "\u2502  \u2502 System Prompts  \u2502  \u2502  User Messages   \u2502  \u2502  Temperature Control   \u2502 \u2502\n",
        "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n",
        "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "                                 \u2502\n",
        "                                 \u2502 Optimized Prompts\n",
        "                                 \u25bc\n",
        "                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "                    \u2502   Azure OpenAI Service     \u2502\n",
        "                    \u2502                            \u2502\n",
        "                    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n",
        "                    \u2502  \u2502  GPT-3.5 Turbo       \u2502  \u2502\n",
        "                    \u2502  \u2502  \u2022 Few-shot learning \u2502  \u2502\n",
        "                    \u2502  \u2502  \u2022 Chain-of-thought  \u2502  \u2502\n",
        "                    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n",
        "                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "\n",
        "\ud83d\udcca Resources Used:\n",
        "  \u2022 Azure OpenAI Service\n",
        "  \u2022 GPT-3.5 Turbo (primary)\n",
        "  \u2022 GPT-4 (comparison testing)\n",
        "\n",
        "\ud83d\udcb0 Estimated Cost: ~$1.00 per lab session\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Setup and Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "\n",
        "# Add utils to path\n",
        "sys.path.append('../../utils')\n",
        "from azure_openai_helper import AzureOpenAIClient, format_messages\n",
        "\n",
        "# Load environment\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize client\n",
        "client = AzureOpenAIClient()\n",
        "\n",
        "print(\"\u2713 Environment loaded\")\n",
        "print(\"\u2713 Azure OpenAI client initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Zero-Shot Prompting\n",
        "\n",
        "**Zero-shot prompting** means asking the model to perform a task without providing any examples.\n",
        "\n",
        "This works well for:\n",
        "- Simple, well-defined tasks\n",
        "- General knowledge questions\n",
        "- Common patterns the model has seen during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Simple classification (zero-shot)\n",
        "zero_shot_prompt = \"\"\"Classify the following banking transaction as one of these categories:\n",
        "- Groceries\n",
        "- Dining\n",
        "- Healthcare\n",
        "- Transportation\n",
        "- Entertainment\n",
        "- Other\n",
        "\n",
        "Transaction: \"Supermercado La Colonia - $45.50\"\n",
        "Category:\"\"\"\n",
        "\n",
        "messages = format_messages(\n",
        "    system_prompt=\"You are a banking transaction classifier.\",\n",
        "    user_message=zero_shot_prompt\n",
        ")\n",
        "\n",
        "response = client.chat_completion(messages, temperature=0.3)\n",
        "print(\"Zero-Shot Classification:\")\n",
        "print(response)\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: One-Shot Prompting\n",
        "\n",
        "**One-shot prompting** provides a single example to guide the model's response format and style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 2: One-shot learning\n",
        "one_shot_prompt = \"\"\"Classify banking transactions into categories.\n",
        "\n",
        "Example:\n",
        "Transaction: \"Gasolinera Uno - $120.00\"\n",
        "Category: Transportation\n",
        "Confidence: High\n",
        "Reason: Gas station purchase\n",
        "\n",
        "Now classify this transaction:\n",
        "Transaction: \"Restaurante El Jard\u00edn - $85.75\"\n",
        "Category:\"\"\"\n",
        "\n",
        "messages = format_messages(\n",
        "    system_prompt=\"You are a banking transaction classifier.\",\n",
        "    user_message=one_shot_prompt\n",
        ")\n",
        "\n",
        "response = client.chat_completion(messages, temperature=0.3)\n",
        "print(\"One-Shot Classification:\")\n",
        "print(response)\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: Few-Shot Prompting\n",
        "\n",
        "**Few-shot prompting** provides multiple examples to establish a clear pattern.\n",
        "\n",
        "This is the most effective technique for:\n",
        "- Consistent formatting\n",
        "- Domain-specific tasks\n",
        "- Complex classification\n",
        "- Custom business logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 3: Few-shot learning with multiple examples\n",
        "few_shot_prompt = \"\"\"Classify banking transactions and detect potential fraud.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Transaction: \"Supermercado La Colonia - $45.50 - 09:23 AM - San Jos\u00e9\"\n",
        "Category: Groceries\n",
        "Fraud Risk: Low\n",
        "Reason: Normal grocery purchase during business hours in usual location\n",
        "\n",
        "Transaction: \"Casino Online - $2,500 - 10:30 PM - Unknown Location\"\n",
        "Category: Gambling\n",
        "Fraud Risk: High\n",
        "Reason: Large gambling transaction at unusual hour from unknown location\n",
        "\n",
        "Transaction: \"Farmacia San Jos\u00e9 - $350 - 11:20 AM - San Jos\u00e9\"\n",
        "Category: Healthcare\n",
        "Fraud Risk: Low\n",
        "Reason: Normal pharmacy purchase during business hours in usual location\n",
        "\n",
        "Transaction: \"International Wire Transfer - $8,000 - 03:15 AM - Foreign Country\"\n",
        "Category: Transfer\n",
        "Fraud Risk: High\n",
        "Reason: Large international transfer at suspicious hour to foreign country\n",
        "\n",
        "Now analyze this transaction:\n",
        "Transaction: \"Tienda Electr\u00f3nica - $1,200 - 07:45 PM - San Jos\u00e9\"\n",
        "Category:\"\"\"\n",
        "\n",
        "messages = format_messages(\n",
        "    system_prompt=\"You are an expert fraud detection system for BNCR.\",\n",
        "    user_message=few_shot_prompt\n",
        ")\n",
        "\n",
        "response = client.chat_completion(messages, temperature=0.3, max_tokens=200)\n",
        "print(\"Few-Shot Classification with Fraud Detection:\")\n",
        "print(response)\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 5: Chain-of-Thought (CoT) Prompting\n",
        "\n",
        "**Chain-of-Thought prompting** encourages the model to show its reasoning process step-by-step.\n",
        "\n",
        "This dramatically improves performance on:\n",
        "- Mathematical calculations\n",
        "- Multi-step reasoning\n",
        "- Complex decision-making\n",
        "- Financial analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 4: Chain-of-Thought for loan eligibility\n",
        "cot_prompt = \"\"\"Determine if a customer is eligible for a personal loan.\n",
        "\n",
        "Eligibility Criteria:\n",
        "- Monthly income >= $2,000\n",
        "- Debt-to-income ratio < 40%\n",
        "- Credit score >= 650\n",
        "- Employment history >= 6 months\n",
        "\n",
        "Customer Profile:\n",
        "- Monthly income: $3,500\n",
        "- Current monthly debt payments: $1,200\n",
        "- Credit score: 720\n",
        "- Employment: 8 months at current job\n",
        "\n",
        "Think through this step-by-step:\n",
        "1. Check each criterion\n",
        "2. Calculate debt-to-income ratio\n",
        "3. Make final decision\n",
        "4. Explain reasoning\"\"\"\n",
        "\n",
        "messages = format_messages(\n",
        "    system_prompt=\"You are a loan officer at BNCR. Always show your reasoning step-by-step.\",\n",
        "    user_message=cot_prompt\n",
        ")\n",
        "\n",
        "response = client.chat_completion(messages, temperature=0.3, max_tokens=400)\n",
        "print(\"Chain-of-Thought Loan Eligibility Analysis:\")\n",
        "print(response)\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 6: Structured Output Prompting\n",
        "\n",
        "For production systems, we often need responses in specific formats like JSON, CSV, or tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 5: JSON output for API integration\n",
        "json_prompt = \"\"\"Analyze this customer inquiry and extract structured information.\n",
        "\n",
        "Customer Message: \"Hi, I'm interested in opening a savings account. I'm 28 years old, \n",
        "work as a software engineer, and want to save for a house down payment in 3 years. \n",
        "I can deposit $500 monthly. What options do you recommend?\"\n",
        "\n",
        "Extract the following information in JSON format:\n",
        "{\n",
        "  \"customer_age\": <age>,\n",
        "  \"occupation\": \"<occupation>\",\n",
        "  \"goal\": \"<savings goal>\",\n",
        "  \"timeline\": \"<time horizon>\",\n",
        "  \"monthly_deposit\": <amount>,\n",
        "  \"product_interest\": \"<product type>\",\n",
        "  \"recommended_products\": [<list of suitable products>]\n",
        "}\"\"\"\n",
        "\n",
        "messages = format_messages(\n",
        "    system_prompt=\"You are a banking assistant that extracts and structures customer information.\",\n",
        "    user_message=json_prompt\n",
        ")\n",
        "\n",
        "response = client.chat_completion(messages, temperature=0.3, max_tokens=300)\n",
        "print(\"Structured JSON Output:\")\n",
        "print(response)\n",
        "\n",
        "# Try to parse the JSON\n",
        "try:\n",
        "    # Extract JSON from response (might be wrapped in markdown)\n",
        "    json_str = response.strip()\n",
        "    if '```json' in json_str:\n",
        "        json_str = json_str.split('```json')[1].split('```')[0]\n",
        "    elif '```' in json_str:\n",
        "        json_str = json_str.split('```')[1].split('```')[0]\n",
        "    \n",
        "    data = json.loads(json_str.strip())\n",
        "    print(\"\\n\u2713 Successfully parsed JSON\")\n",
        "    print(json.dumps(data, indent=2))\n",
        "except Exception as e:\n",
        "    print(f\"\\n\u26a0 Could not parse JSON: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 7: Role-Based Prompting\n",
        "\n",
        "Assigning specific roles helps the model adopt appropriate expertise and communication style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 6: Different roles for different audiences\n",
        "question = \"What is compound interest and how does it work?\"\n",
        "\n",
        "roles = [\n",
        "    (\"You are a financial advisor explaining to a 10-year-old child.\", \"Child\"),\n",
        "    (\"You are a bank teller explaining to an average customer.\", \"Customer\"),\n",
        "    (\"You are a finance professor teaching MBA students.\", \"MBA Student\")\n",
        "]\n",
        "\n",
        "for system_prompt, audience in roles:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Audience: {audience}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "    \n",
        "    messages = format_messages(system_prompt, question)\n",
        "    response = client.chat_completion(messages, temperature=0.7, max_tokens=200)\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 8: Handling Edge Cases and Constraints\n",
        "\n",
        "Production prompts must handle edge cases, invalid inputs, and business constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 7: Robust prompt with constraints\n",
        "robust_prompt = \"\"\"You are a customer service chatbot for BNCR with the following constraints:\n",
        "\n",
        "CAPABILITIES:\n",
        "- Answer questions about products and services\n",
        "- Provide general banking information\n",
        "- Guide customers to appropriate resources\n",
        "\n",
        "LIMITATIONS:\n",
        "- Cannot access customer account information\n",
        "- Cannot perform transactions\n",
        "- Cannot provide personalized financial advice\n",
        "- Cannot discuss other banks or competitors\n",
        "\n",
        "RULES:\n",
        "1. If asked about account details, politely explain you cannot access accounts\n",
        "2. If asked to perform transactions, direct to online banking or branch\n",
        "3. If asked for financial advice, recommend speaking with an advisor\n",
        "4. If asked about competitors, focus on BNCR's offerings\n",
        "5. Always be professional, helpful, and security-conscious\n",
        "6. Never make up information - admit when you don't know\n",
        "\n",
        "Respond to this customer:\"\"\"\n",
        "\n",
        "test_queries = [\n",
        "    \"What's my account balance?\",\n",
        "    \"Can you transfer $500 to my friend?\",\n",
        "    \"Should I invest in stocks or bonds?\",\n",
        "    \"Is your bank better than Banco Popular?\",\n",
        "    \"What are your savings account interest rates?\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Customer: {query}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "    \n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": robust_prompt},\n",
        "        {\"role\": \"user\", \"content\": query}\n",
        "    ]\n",
        "    \n",
        "    response = client.chat_completion(messages, temperature=0.5, max_tokens=200)\n",
        "    print(f\"Assistant: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 9: Prompt Templates and Reusability\n",
        "\n",
        "Create reusable prompt templates for common banking scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 8: Prompt template system\n",
        "class BankingPromptTemplates:\n",
        "    \n",
        "    @staticmethod\n",
        "    def fraud_detection(transaction_details):\n",
        "        return f\"\"\"Analyze this transaction for fraud risk:\n",
        "\n",
        "{transaction_details}\n",
        "\n",
        "Provide:\n",
        "1. Risk Level (Low/Medium/High)\n",
        "2. Risk Factors identified\n",
        "3. Recommended action\n",
        "4. Confidence score (0-100%)\n",
        "\n",
        "Format as JSON.\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def product_recommendation(customer_profile):\n",
        "        return f\"\"\"Based on this customer profile, recommend suitable banking products:\n",
        "\n",
        "{customer_profile}\n",
        "\n",
        "For each recommended product, provide:\n",
        "1. Product name\n",
        "2. Why it's suitable\n",
        "3. Key benefits\n",
        "4. Important considerations\n",
        "\n",
        "Limit to top 3 recommendations.\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def customer_sentiment(message):\n",
        "        return f\"\"\"Analyze the sentiment and urgency of this customer message:\n",
        "\n",
        "\"{message}\"\n",
        "\n",
        "Provide:\n",
        "- Sentiment: (Positive/Neutral/Negative)\n",
        "- Urgency: (Low/Medium/High/Critical)\n",
        "- Main concern: (brief description)\n",
        "- Suggested response priority: (1-5, where 5 is highest)\n",
        "- Recommended department: (Customer Service/Technical/Fraud/Loans/etc.)\n",
        "\n",
        "Format as JSON.\"\"\"\n",
        "\n",
        "# Test the templates\n",
        "templates = BankingPromptTemplates()\n",
        "\n",
        "# Test 1: Fraud detection\n",
        "transaction = \"\"\"Transaction ID: TXN12345\n",
        "Amount: $5,000\n",
        "Merchant: Online Casino\n",
        "Time: 2:30 AM\n",
        "Location: Foreign Country\n",
        "Customer's usual location: San Jos\u00e9, Costa Rica\n",
        "Customer's usual transaction amount: $50-200\"\"\"\n",
        "\n",
        "print(\"Test 1: Fraud Detection\")\n",
        "print(\"=\"*80)\n",
        "messages = format_messages(\n",
        "    \"You are a fraud detection expert at BNCR.\",\n",
        "    templates.fraud_detection(transaction)\n",
        ")\n",
        "response = client.chat_completion(messages, temperature=0.3, max_tokens=300)\n",
        "print(response)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Test 2: Sentiment analysis\n",
        "customer_message = \"\"\"I've been trying to access my account for 3 days and your app keeps crashing! \n",
        "I have bills to pay and I'm getting very frustrated. This is unacceptable!\"\"\"\n",
        "\n",
        "print(\"Test 2: Sentiment Analysis\")\n",
        "print(\"=\"*80)\n",
        "messages = format_messages(\n",
        "    \"You are a customer service analyst at BNCR.\",\n",
        "    templates.customer_sentiment(customer_message)\n",
        ")\n",
        "response = client.chat_completion(messages, temperature=0.3, max_tokens=250)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 10: Measuring Prompt Quality\n",
        "\n",
        "How do we know if our prompts are good? Let's establish metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 9: A/B testing different prompts\n",
        "import time\n",
        "\n",
        "def evaluate_prompt(system_prompt, user_message, test_name, runs=3):\n",
        "    \"\"\"\n",
        "    Evaluate a prompt across multiple runs\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    total_tokens = 0\n",
        "    total_time = 0\n",
        "    \n",
        "    for i in range(runs):\n",
        "        start_time = time.time()\n",
        "        messages = format_messages(system_prompt, user_message)\n",
        "        \n",
        "        response = client.client.chat.completions.create(\n",
        "            model=client.gpt35_deployment,\n",
        "            messages=messages,\n",
        "            temperature=0.7,\n",
        "            max_tokens=200\n",
        "        )\n",
        "        \n",
        "        elapsed = time.time() - start_time\n",
        "        \n",
        "        results.append(response.choices[0].message.content)\n",
        "        total_tokens += response.usage.total_tokens\n",
        "        total_time += elapsed\n",
        "    \n",
        "    return {\n",
        "        \"test_name\": test_name,\n",
        "        \"responses\": results,\n",
        "        \"avg_tokens\": total_tokens / runs,\n",
        "        \"avg_time\": total_time / runs,\n",
        "        \"consistency\": len(set(results)) == 1  # All responses identical\n",
        "    }\n",
        "\n",
        "# Compare two approaches\n",
        "question = \"What documents do I need to open a savings account?\"\n",
        "\n",
        "# Prompt A: Simple\n",
        "prompt_a = \"You are a helpful banking assistant.\"\n",
        "\n",
        "# Prompt B: Detailed\n",
        "prompt_b = \"\"\"You are a banking assistant at BNCR. When answering questions about account opening:\n",
        "1. List required documents clearly\n",
        "2. Mention any age requirements\n",
        "3. Note minimum deposit if applicable\n",
        "4. Keep response concise (under 100 words)\"\"\"\n",
        "\n",
        "print(\"Evaluating Prompt A (Simple)...\")\n",
        "result_a = evaluate_prompt(prompt_a, question, \"Prompt A\")\n",
        "\n",
        "print(\"Evaluating Prompt B (Detailed)...\")\n",
        "result_b = evaluate_prompt(prompt_b, question, \"Prompt B\")\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARISON RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for result in [result_a, result_b]:\n",
        "    print(f\"\\n{result['test_name']}:\")\n",
        "    print(f\"  Average tokens: {result['avg_tokens']:.1f}\")\n",
        "    print(f\"  Average time: {result['avg_time']:.2f}s\")\n",
        "    print(f\"  Consistent: {result['consistency']}\")\n",
        "    print(f\"\\n  Sample response:\\n  {result['responses'][0][:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf Practical Exercise 1: Credit Card Application Screener\n",
        "\n",
        "Create a prompt that screens credit card applications and provides structured output.\n",
        "\n",
        "Requirements:\n",
        "- Use few-shot learning with 2-3 examples\n",
        "- Output must be valid JSON\n",
        "- Include eligibility decision, reasons, and recommended card tier\n",
        "- Handle edge cases (missing info, unrealistic values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create credit card application screener\n",
        "# TODO: Test with various applicant profiles\n",
        "# TODO: Validate JSON output\n",
        "\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf Practical Exercise 2: Intelligent FAQ Router\n",
        "\n",
        "Build a system that routes customer questions to the appropriate department.\n",
        "\n",
        "Requirements:\n",
        "- Use chain-of-thought reasoning\n",
        "- Classify into: Accounts, Cards, Loans, Technical, Fraud, General\n",
        "- Provide urgency score (1-5)\n",
        "- Suggest if human escalation is needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create FAQ routing system\n",
        "# TODO: Test with various customer questions\n",
        "# TODO: Measure accuracy\n",
        "\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf Practical Exercise 3: Prompt Optimization Challenge\n",
        "\n",
        "You have a prompt that works but uses too many tokens. Optimize it!\n",
        "\n",
        "Original task: \"Summarize customer feedback and extract key issues\"\n",
        "\n",
        "Goals:\n",
        "- Reduce token usage by 30%\n",
        "- Maintain or improve output quality\n",
        "- Keep response time under 2 seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample customer feedback\n",
        "feedback = \"\"\"I've been a customer for 5 years and generally happy with the service. \n",
        "However, the mobile app has been very slow lately and sometimes crashes when I try to \n",
        "transfer money. The customer service team is helpful but wait times are too long - \n",
        "I waited 45 minutes last week. Also, I think the fees for international transfers are \n",
        "higher than other banks. On the positive side, I love the new savings account features \n",
        "and the interest rates are competitive.\"\"\"\n",
        "\n",
        "# TODO: Create optimized prompt\n",
        "# TODO: Compare with verbose version\n",
        "# TODO: Measure token usage and quality\n",
        "\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Best Practices\n",
        "\n",
        "### Key Techniques Learned:\n",
        "\n",
        "1. **Zero-Shot**: Direct task description, no examples\n",
        "2. **One-Shot**: Single example to guide format\n",
        "3. **Few-Shot**: Multiple examples for consistency\n",
        "4. **Chain-of-Thought**: Step-by-step reasoning\n",
        "5. **Structured Output**: JSON, tables, specific formats\n",
        "6. **Role-Based**: Assign expertise and communication style\n",
        "\n",
        "### Prompt Engineering Best Practices:\n",
        "\n",
        "**Be Specific**\n",
        "- Clear instructions beat vague requests\n",
        "- Define expected output format\n",
        "- Specify constraints and limitations\n",
        "\n",
        "**Provide Context**\n",
        "- Include relevant background information\n",
        "- Define the role and expertise level\n",
        "- Clarify the audience\n",
        "\n",
        "**Use Examples**\n",
        "- Few-shot learning dramatically improves consistency\n",
        "- Examples should cover edge cases\n",
        "- Show the exact format you want\n",
        "\n",
        "**Iterate and Test**\n",
        "- Test prompts with multiple inputs\n",
        "- Measure consistency across runs\n",
        "- A/B test different approaches\n",
        "- Monitor token usage and costs\n",
        "\n",
        "**Handle Edge Cases**\n",
        "- Define what to do with invalid inputs\n",
        "- Set clear boundaries (what you can/can't do)\n",
        "- Include fallback responses\n",
        "\n",
        "**Optimize for Production**\n",
        "- Balance quality vs. token usage\n",
        "- Use templates for reusability\n",
        "- Version control your prompts\n",
        "- Document what works and why\n",
        "\n",
        "### Banking-Specific Guidelines:\n",
        "\n",
        "- **Security First**: Never request or expose sensitive data\n",
        "- **Compliance**: Ensure responses align with regulations\n",
        "- **Accuracy**: Financial information must be precise\n",
        "- **Transparency**: Make limitations clear to users\n",
        "- **Consistency**: Banking requires reliable, predictable responses\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "In Lab 07, we'll apply these techniques to build a complete customer service chatbot with advanced conversation management.\n",
        "\n",
        "---\n",
        "\n",
        "**Questions or Issues?**  \n",
        "Contact: Manuela Larrea | manuela.larrea@idataglobal.com"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}